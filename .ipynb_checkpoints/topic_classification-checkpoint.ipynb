{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a27c8b59",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "In this project, we aim to use LLM to perform topic classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5d700fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI, AzureOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate, \n",
    "    MessagesPlaceholder, \n",
    "    SystemMessagePromptTemplate, \n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cebbe0",
   "metadata": {},
   "source": [
    "#### 1. Create document chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc1aa91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_name = 'ABB Review_03_2023_layout complete_EN_300dpi'\n",
    "article_name = 'perfect_partners'\n",
    "article_range = [41, 45]\n",
    "loader = PyMuPDFLoader(\"./papers/\"+issue_name+\".pdf\")\n",
    "raw_documents = loader.load()[article_range[0]:article_range[-1]+1]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=100)\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3233e486",
   "metadata": {},
   "source": [
    "#### 2. Topic classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40e5e6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available topics\n",
    "topics = ['Tech and product insights', 'Market dynamics', 'Operational transformation', \n",
    "          'Sustainability initiatives', 'Customer experience', 'Industry challenges and opportunities', \n",
    "          'Strategic collaborations', 'Strategy innovation', 'General overview']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e1b2636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LLM (completion)\n",
    "llm = AzureOpenAI(\n",
    "    deployment_name=\"deployment-5af509f3323342ee919481751c6f8b7d\",\n",
    "    model_name=\"text-davinci-003\",\n",
    "    openai_api_base=\"https://abb-chcrc.openai.azure.com/\",\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    openai_api_type=\"azure\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cded7ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Given the following text, output which focal points from the following list are most relevant?.\n",
    "\n",
    "        [text]: {text} \\n\n",
    "        [Focal points]: {topics}\n",
    "        \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"text\", \"topics\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "377ff647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/9th docs.\n",
      "Processing 3/9th docs.\n",
      "Processing 5/9th docs.\n",
      "Processing 7/9th docs.\n",
      "Processing 9/9th docs.\n"
     ]
    }
   ],
   "source": [
    "llm_response = []\n",
    "for i, doc in enumerate(documents):\n",
    "    if i%2==0:\n",
    "        print(f\"Processing {i+1}/{len(documents)}th docs.\")\n",
    "    response = llm.predict(prompt.format(text=doc.page_content, topics=topics))\n",
    "    llm_response.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2fbe1096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nTech and product insights, Operational transformation, Sustainability initiatives, Strategic collaborations, and Industry challenges and opportunities.',\n",
       " '\\nTech and product insights, Sustainability initiatives, Strategic collaborations, Strategy innovation',\n",
       " '\\nTech and product insights, Sustainability initiatives, Strategic collaborations.',\n",
       " '\\nTech and product insights\\nMarket dynamics\\nStrategic collaborations\\nSustainability initiatives\\nIndustry challenges and opportunities\\nOperational transformation',\n",
       " '\\nSustainability Initiatives, Strategic Collaborations, Strategy Innovation',\n",
       " '\\nSustainability initiatives, Operational transformation, Tech and product insights, and Strategy innovation.',\n",
       " '\\nTech and product insights, Sustainability initiatives, Strategic collaborations, and Strategy innovation.',\n",
       " '\\nTech and product insights\\nOperational transformation\\nSustainability initiatives\\nStrategic collaborations\\nStrategy innovation',\n",
       " '\\nSustainability initiatives, Strategic collaborations, Operational transformation.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07ad9913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sustainability initiatives': 8,\n",
       " 'Tech and product insights': 7,\n",
       " 'Strategic collaborations': 7,\n",
       " 'Operational transformation': 5,\n",
       " 'Strategy innovation': 4,\n",
       " 'Industry challenges and opportunities': 2,\n",
       " 'Market dynamics': 1,\n",
       " 'Customer experience': 0}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count \n",
    "topic_classifier = {}\n",
    "for topic in topics[:-1]:\n",
    "    topic_classifier[topic] = 0\n",
    "    for response in llm_response:\n",
    "        if topic in response:\n",
    "            topic_classifier[topic] += 1\n",
    "\n",
    "# Decide relevant topics\n",
    "selected_topics = dict(sorted(topic_classifier.items(), key=lambda item: item[1], reverse=True))\n",
    "selected_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad55e35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
